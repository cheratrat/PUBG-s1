{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pubgK2.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cheratrat/PUBG-s1/blob/master/pubgK2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orLUcj_scclK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from timeit import default_timer as timer\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import random\n",
        "random.seed(42)\n",
        "\n",
        "import os\n",
        "assert os.system(\"pip install ultimate==2.15.1\")==0\n",
        "\n",
        "from ultimate.mlp import MLP\n",
        "import gc, sys\n",
        "gc.enable()\n",
        "\n",
        "NUM = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwVs4465cgh7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "d41a2e17-d939-4306-81d5-d2a9ad45968f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/Drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDvfBaVWchv3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIR=\"/content/Drive/My Drive/Colab Notebooks/pubg\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjmd1oYwcAGj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "cd029e4f-f3b8-4e67-8c3c-f66db2e25bdc"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "import lightgbm as lgb\n",
        "\"\"\"\n",
        "changed from https://www.kaggle.com/anycode/simple-nn-baseline\n",
        "\n",
        "to run this kernel, pip install ultimate first from your custom packages\n",
        "\"\"\"\n",
        "import gc, sys\n",
        "gc.enable()\n",
        "\n",
        "def feature_engineering(is_train=True,debug=True):\n",
        "    test_idx = None\n",
        "    if is_train: \n",
        "        print(\"processing train.csv\")\n",
        "        if debug == True:\n",
        "            df = pd.read_csv(INPUT_DIR + '/tt/train_V2.csv', nrows=10000)\n",
        "        else:\n",
        "            df = pd.read_csv(INPUT_DIR + '/tt/train_V2.csv')           \n",
        "\n",
        "        df = df[df['maxPlace'] > 1]\n",
        "    else:\n",
        "        print(\"processing test.csv\")\n",
        "        df = pd.read_csv(INPUT_DIR + '/tt/test_V2.csv')\n",
        "        test_idx = df.Id\n",
        "    \n",
        "    print(\"remove some columns\")\n",
        "    target = 'winPlacePerc'\n",
        "\n",
        "    print(\"Adding Features\")\n",
        " \n",
        "    df['headshotrate'] = df['kills']/df['headshotKills']\n",
        "    df['killStreakrate'] = df['killStreaks']/df['kills']\n",
        "    df['healthitems'] = df['heals'] + df['boosts']\n",
        "    df['totalDistance'] = df['rideDistance'] + df[\"walkDistance\"] + df[\"swimDistance\"]\n",
        "    df['killPlace_over_maxPlace'] = df['killPlace'] / df['maxPlace']\n",
        "    df['headshotKills_over_kills'] = df['headshotKills'] / df['kills']\n",
        "    df['distance_over_weapons'] = df['totalDistance'] / df['weaponsAcquired']\n",
        "    df['walkDistance_over_heals'] = df['walkDistance'] / df['heals']\n",
        "    df['walkDistance_over_kills'] = df['walkDistance'] / df['kills']\n",
        "    df['killsPerWalkDistance'] = df['kills'] / df['walkDistance']\n",
        "    df[\"skill\"] = df[\"headshotKills\"] + df[\"roadKills\"]\n",
        "\n",
        "    df[df == np.Inf] = np.NaN\n",
        "    df[df == np.NINF] = np.NaN\n",
        "    \n",
        "    print(\"Removing Na's From DF\")\n",
        "    df.fillna(0, inplace=True)\n",
        "\n",
        "    \n",
        "    features = list(df.columns)\n",
        "    features.remove(\"Id\")\n",
        "    features.remove(\"matchId\")\n",
        "    features.remove(\"groupId\")\n",
        "    features.remove(\"matchType\")\n",
        "    \n",
        "    y = None\n",
        "    \n",
        "    \n",
        "    if is_train: \n",
        "        print(\"get target\")\n",
        "        y = np.array(df.groupby(['matchId','groupId'])[target].agg('mean'), dtype=np.float64)\n",
        "        features.remove(target)\n",
        "\n",
        "    print(\"get group mean feature\")\n",
        "    agg = df.groupby(['matchId','groupId'])[features].agg('mean')\n",
        "    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n",
        "    \n",
        "    if is_train: df_out = agg.reset_index()[['matchId','groupId']]\n",
        "    else: df_out = df[['matchId','groupId']]\n",
        "\n",
        "    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n",
        "    df_out = df_out.merge(agg_rank, suffixes=[\"_mean\", \"_mean_rank\"], how='left', on=['matchId', 'groupId'])\n",
        "    \n",
        "    print(\"get group max feature\")\n",
        "    agg = df.groupby(['matchId','groupId'])[features].agg('max')\n",
        "    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n",
        "    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n",
        "    df_out = df_out.merge(agg_rank, suffixes=[\"_max\", \"_max_rank\"], how='left', on=['matchId', 'groupId'])\n",
        "    \n",
        "    print(\"get group min feature\")\n",
        "    agg = df.groupby(['matchId','groupId'])[features].agg('min')\n",
        "    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n",
        "    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n",
        "    df_out = df_out.merge(agg_rank, suffixes=[\"_min\", \"_min_rank\"], how='left', on=['matchId', 'groupId'])\n",
        "    \n",
        "    print(\"get group size feature\")\n",
        "    agg = df.groupby(['matchId','groupId']).size().reset_index(name='group_size')\n",
        "    df_out = df_out.merge(agg, how='left', on=['matchId', 'groupId'])\n",
        "    \n",
        "    print(\"get match mean feature\")\n",
        "    agg = df.groupby(['matchId'])[features].agg('mean').reset_index()\n",
        "    df_out = df_out.merge(agg, suffixes=[\"\", \"_match_mean\"], how='left', on=['matchId'])\n",
        "    \n",
        "    print(\"get match size feature\")\n",
        "    agg = df.groupby(['matchId']).size().reset_index(name='match_size')\n",
        "    df_out = df_out.merge(agg, how='left', on=['matchId'])\n",
        "    \n",
        "    df_out.drop([\"matchId\", \"groupId\"], axis=1, inplace=True)\n",
        "\n",
        "    X = df_out\n",
        "    \n",
        "    feature_names = list(df_out.columns)\n",
        "\n",
        "    del df, df_out, agg, agg_rank\n",
        "    gc.collect()\n",
        "\n",
        "    return X, y, feature_names, test_idx\n",
        "  \n",
        "x_train, y_train, train_columns, _ = feature_engineering(True,False)\n",
        "x_test, _, _ , test_idx = feature_engineering(False,True)\n",
        "  \n",
        "  # Thanks and credited to https://www.kaggle.com/gemartin who created this wonderful mem reducer\n",
        "def reduce_mem_usage(df):\n",
        "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
        "        to reduce memory usage.        \n",
        "    \"\"\"\n",
        "    start_mem = df.memory_usage().sum() \n",
        "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "        \n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        else:\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "    end_mem = df.memory_usage().sum() \n",
        "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "    \n",
        "    return df\n",
        "\n",
        "x_train = reduce_mem_usage(x_train)\n",
        "x_test = reduce_mem_usage(x_test)\n",
        "\n",
        "#excluded_features = []\n",
        "#use_cols = [col for col in df_train.columns if col not in excluded_features]\n",
        "\n",
        "train_index = round(int(x_train.shape[0]*0.8))\n",
        "dev_X = x_train[:train_index] \n",
        "val_X = x_train[train_index:]\n",
        "dev_y = y_train[:train_index] \n",
        "val_y = y_train[train_index:] \n",
        "gc.collect();\n",
        "\n",
        "# custom function to run light gbm model\n",
        "def run_lgb(train_X, train_y, val_X, val_y, x_test):\n",
        "    params = {\"objective\" : \"regression\", \"metric\" : \"mae\", 'n_estimators':20000, 'early_stopping_rounds':200,\n",
        "              \"num_leaves\" : 31, \"learning_rate\" : 0.05, \"bagging_fraction\" : 0.7,\n",
        "               \"bagging_seed\" : 0, \"num_threads\" : 4,\"colsample_bytree\" : 0.7\n",
        "             }\n",
        "    \n",
        "    lgtrain = lgb.Dataset(train_X, label=train_y)\n",
        "    lgval = lgb.Dataset(val_X, label=val_y)\n",
        "    model = lgb.train(params, lgtrain, valid_sets=[lgtrain, lgval], early_stopping_rounds=200, verbose_eval=1000)\n",
        "    \n",
        "    pred_test_y = model.predict(x_test, num_iteration=model.best_iteration)\n",
        "    return pred_test_y, model\n",
        "\n",
        "# Training the model #\n",
        "pred_test, model = run_lgb(dev_X, dev_y, val_X, val_y, x_test)\n",
        "\n",
        "df_sub = pd.read_csv(INPUT_DIR + '/tt/sample_submission_V2.csv')\n",
        "df_test = pd.read_csv(INPUT_DIR + '/tt/test_V2.csv')\n",
        "df_sub['winPlacePerc'] = pred_test\n",
        "# Restore some columns\n",
        "df_sub = df_sub.merge(df_test[[\"Id\", \"matchId\", \"groupId\", \"maxPlace\", \"numGroups\"]], on=\"Id\", how=\"left\")\n",
        "\n",
        "# Sort, rank, and assign adjusted ratio\n",
        "df_sub_group = df_sub.groupby([\"matchId\", \"groupId\"]).first().reset_index()\n",
        "df_sub_group[\"rank\"] = df_sub_group.groupby([\"matchId\"])[\"winPlacePerc\"].rank()\n",
        "df_sub_group = df_sub_group.merge(\n",
        "    df_sub_group.groupby(\"matchId\")[\"rank\"].max().to_frame(\"max_rank\").reset_index(), \n",
        "    on=\"matchId\", how=\"left\")\n",
        "df_sub_group[\"adjusted_perc\"] = (df_sub_group[\"rank\"] - 1) / (df_sub_group[\"numGroups\"] - 1)\n",
        "\n",
        "df_sub = df_sub.merge(df_sub_group[[\"adjusted_perc\", \"matchId\", \"groupId\"]], on=[\"matchId\", \"groupId\"], how=\"left\")\n",
        "df_sub[\"winPlacePerc\"] = df_sub[\"adjusted_perc\"]\n",
        "\n",
        "# Deal with edge cases\n",
        "df_sub.loc[df_sub.maxPlace == 0, \"winPlacePerc\"] = 0\n",
        "df_sub.loc[df_sub.maxPlace == 1, \"winPlacePerc\"] = 1\n",
        "\n",
        "# Align with maxPlace\n",
        "subset = df_sub.loc[df_sub.maxPlace > 1]\n",
        "gap = 1.0 / (subset.maxPlace.values - 1)\n",
        "new_perc = np.around(subset.winPlacePerc.values / gap) * gap\n",
        "df_sub.loc[df_sub.maxPlace > 1, \"winPlacePerc\"] = new_perc\n",
        "\n",
        "# Edge case\n",
        "df_sub.loc[(df_sub.maxPlace > 1) & (df_sub.numGroups == 1), \"winPlacePerc\"] = 0\n",
        "assert df_sub[\"winPlacePerc\"].isnull().sum() == 0\n",
        "\n",
        "df_sub[[\"Id\", \"winPlacePerc\"]].to_csv(\"submission_adjusted.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing train.csv\n",
            "remove some columns\n",
            "Adding Features\n",
            "Removing Na's From DF\n",
            "get target\n",
            "get group mean feature\n",
            "get group max feature\n",
            "get group min feature\n",
            "get group size feature\n",
            "get match mean feature\n",
            "get match size feature\n",
            "processing test.csv\n",
            "remove some columns\n",
            "Adding Features\n",
            "Removing Na's From DF\n",
            "get group mean feature\n",
            "get group max feature\n",
            "get group min feature\n",
            "get group size feature\n",
            "get match mean feature\n",
            "get match size feature\n",
            "Memory usage of dataframe is 4021060096.00 MB\n",
            "Memory usage after optimization is: 948516192.00 MB\n",
            "Decreased by 76.4%\n",
            "Memory usage of dataframe is 3837401216.00 MB\n",
            "Memory usage after optimization is: 903259258.00 MB\n",
            "Decreased by 76.5%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:123: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 200 rounds.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}